{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50197ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b93997",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d83a1a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38}\n"
     ]
    }
   ],
   "source": [
    "characters = sorted(set(text))\n",
    "# print(characters)\n",
    "\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "# print(char_to_index)\n",
    "\n",
    "\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
    "# print(index_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4368b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []\n",
    "\n",
    "# sentences will have sentences and\n",
    "# next_char will try to predict next word in sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb74e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])\n",
    "    \n",
    "    # print(next_char)\n",
    "    \n",
    "    #simply this loop is breaking all the words in chars\n",
    "    #Eg :=.   \n",
    "    #    next_char = ['Hello', 'ello,', 'llo, ', 'lo, h', 'o,\n",
    "    #     ho', ', how', ' how ', 'how a', 'ow ar', '\n",
    "    #     w are', ' are ', 'are y', 're yo', 'e you', ' you', 'you ', \n",
    "    #    'ou to', 'u tod', ' toda', 'today']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac15b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  code is creating a data representation for \n",
    "# training a neural network. It encodes sequences of \n",
    "# characters (x) and the next character after each sequence (y) \n",
    "# in a binary format, where 1 indicates the presence of a \n",
    "# character at a specific position.\n",
    "\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=bool)\n",
    "\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db496e5",
   "metadata": {},
   "source": [
    "# making neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a826511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db7a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#sequential?? a simple stack layer where \n",
    "# each layer has one input tensor and one output tensor\n",
    "\n",
    "\n",
    "\n",
    "model.add(LSTM(128,input_shape=(SEQ_LENGTH,len(characters))))\n",
    "#adding a lstm layer with 128neurons to model\n",
    "\n",
    "model.add(Dense(len(characters)))\n",
    "# This specifies a dense layer with a number of units\n",
    "# equal to the length of the characters\n",
    "# character=['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.',\n",
    "#            '3', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', \n",
    "#            'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "# The number of units in the dense layer often \n",
    "# corresponds to the number of classes or unique\n",
    "# elements in the output.\n",
    "\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "# it takes a set of numbers and converts \n",
    "# them into a probability distribution,\n",
    "# meaning it makes them look like probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58cda6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 223s 292ms/step - loss: 2.6923\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 167s 256ms/step - loss: 2.2990\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 141s 217ms/step - loss: 2.1811\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 102s 157ms/step - loss: 2.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x215cacbdf90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec70a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf60333",
   "metadata": {},
   "source": [
    "# generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6046aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3a7ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ermione:\n",
      "take the boy to you: he so trough mand of the the the to the mand and and and the fored in the with the pronter and the sore the the the the the the doren and the the the the the ward the wart in that the pranter of the the the the the for the the the with the mand and and and and the wardes for the dound hath the there the ware \n",
      "ts; therefore, be bold.\n",
      "\n",
      "northumberland:\n",
      "what the the thes i lave the grownis do the treen.\n",
      "\n",
      "nore:\n",
      "in the sarke thou the wart and with in here porese my word in the reant.\n",
      "\n",
      "kender:\n",
      "and and are the will so merest the shath and some that bather wart but the for the sout and of the freth here wall is nous of the wing weat the ward mand and t\n",
      "ou, on my life, and holds you dear\n",
      "as havent in to his the for the wall the mound in the sore in beis of is for made of agling of hos ow the dorent.\n",
      "\n",
      "king ard in this mand werrdend hard some il no saen his forle the keand for urence the the beand\n",
      "nourthe book mand as mane,\n",
      "here the thar are the care the cavess frath,\n",
      "the than the the in t\n",
      "ntes:\n",
      "no, in good earnest.\n",
      "how sometimes lond and nom that the thee pand fore:\n",
      "and hear i wy the grapnet pate and betes in thath but fare?\n",
      "\n",
      "and if of that reant thom, wire to wisth\n",
      "whet fom list love worde eremen,\n",
      "and tho sore, tha comancote tene stand the sincechand heard panet the mord,\n",
      "and the love, a tond thin mant, not the qooused so\n",
      " terms,\n",
      "nor bide the encounter of assailed and and brosen,\n",
      "it soam so sont word sall os il;\n",
      "and thy comest ou s inged i hpreses'e sour,\n",
      "camano:\n",
      "i list putane at, bererco nom in bood wo sher.\n",
      "\n",
      "ars in fore hour, when wor widte thee the wing.\n",
      "\n",
      "ford ofer art thou amepent:\n",
      "my form is mamthe fromest dich the feall.\n",
      "\n",
      "tore:\n",
      "and face mad poster th\n",
      "ll all the rest confound.\n",
      "\n",
      "duchess of yor parethon, lavd thou wath net.\n",
      "\n",
      "festice it thit with are if weard thin ademy unencblteat's to fet the reindst in willt.\n",
      "\n",
      "will as work forke, i with thy cace hourts thle wath thean?\n",
      "\n",
      "owe mivime not ul, as i the ballake wigh with and noted?\n",
      "\n",
      "moucargis:\n",
      "what i fore. and balace wald friclart if this ke\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df4e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7410bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d9598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415e3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e87a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
