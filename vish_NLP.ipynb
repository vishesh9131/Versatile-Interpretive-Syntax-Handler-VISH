{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50197ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b93997",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83a1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))\n",
    "# print(characters)\n",
    "\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "# print(char_to_index)\n",
    "\n",
    "\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
    "# print(index_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4368b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []\n",
    "\n",
    "# sentences will have sentences and\n",
    "# next_char will try to predict next word in sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddb74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])\n",
    "    \n",
    "    # print(next_char)\n",
    "    \n",
    "    #simply this loop is breaking all the words in chars\n",
    "    #Eg :=.   \n",
    "    #    next_char = ['Hello', 'ello,', 'llo, ', 'lo, h', 'o,\n",
    "    #     ho', ', how', ' how ', 'how a', 'ow ar', '\n",
    "    #     w are', ' are ', 'are y', 're yo', 'e you', ' you', 'you ', \n",
    "    #    'ou to', 'u tod', ' toda', 'today']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac15b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  code is creating a data representation for \n",
    "# training a neural network. It encodes sequences of \n",
    "# characters (x) and the next character after each sequence (y) \n",
    "# in a binary format, where 1 indicates the presence of a \n",
    "# character at a specific position.\n",
    "\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=bool)\n",
    "\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db496e5",
   "metadata": {},
   "source": [
    "# making neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a826511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db7a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#sequential?? a simple stack layer where \n",
    "# each layer has one input tensor and one output tensor\n",
    "\n",
    "\n",
    "\n",
    "model.add(LSTM(128,input_shape=(SEQ_LENGTH,len(characters))))\n",
    "#adding a lstm layer with 128neurons to model\n",
    "\n",
    "model.add(Dense(len(characters)))\n",
    "# This specifies a dense layer with a number of units\n",
    "# equal to the length of the characters\n",
    "# character=['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.',\n",
    "#            '3', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', \n",
    "#            'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "# The number of units in the dense layer often \n",
    "# corresponds to the number of classes or unique\n",
    "# elements in the output.\n",
    "\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "# it takes a set of numbers and converts \n",
    "# them into a probability distribution,\n",
    "# meaning it makes them look like probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58cda6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 31s 48ms/step - loss: 2.6889\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 32s 49ms/step - loss: 2.2997\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 31s 48ms/step - loss: 2.1830\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 31s 48ms/step - loss: 2.0928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15b160dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec70a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf60333",
   "metadata": {},
   "source": [
    "# generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6046aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3a7ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilt be satisfied.\n",
      "\n",
      "juliet:\n",
      "indeed, i neve me the south the beather will his the sored the forther and the fored he meatere the heard,\n",
      "and sould the fore ou the king of the sone.\n",
      "\n",
      "rome if or is mare the will so for the heard the shere,\n",
      "the south the sone the hear of the court.\n",
      "\n",
      "hereri:\n",
      "and i arderde:\n",
      "and so my more to me thou have the grou\n",
      "s thou rescue him from foul despair?\n",
      "\n",
      "bour and is come:\n",
      "of there sould so ford if the bist the singed is thou see the sane.\n",
      "\n",
      "areer:\n",
      "eristle:\n",
      "hour the love, thou hear s, but the soust the king.\n",
      "\n",
      "lereice:\n",
      "here mare of tore ard in the seant the ingering ingerore.\n",
      "\n",
      "hareave:\n",
      "i wart of all of uree the prould the singer in the come of in;\n",
      "and i \n",
      " out\n",
      "and makes himself an artificial nigh, of his dead, i seans\n",
      "enot hou the gover hath all then meard in wore the gee to gake of theres,\n",
      "i will to fored fare ous nost, and the med to here,\n",
      "in ming his with the ore i bered that hish ant sour has hald cone.\n",
      "\n",
      "burien:\n",
      "thou hime the bence that the sien thou dave,\n",
      "and with sear home, that i fo\n",
      "ht.\n",
      "\n",
      "king edward iv:\n",
      "to tell thee plain, and ferenss thou chould word.\n",
      "\n",
      "berying:\n",
      "i will rowe thas boted arderes of auk beses;\n",
      "and you there to my lome dard as i of of some.\n",
      "\n",
      "larither:\n",
      "and be that aulipe the not me af winco feor i masdfard,\n",
      "ago to go so the beiswris i and in theiss tore oferomeree;\n",
      "and i an the reave there comentence thes \n",
      "\n",
      "nor brass nor stone nor parchment bearseld\n",
      "and sure, for hame to thee goon of nor the gare?\n",
      "\n",
      "jolind:\n",
      "whos i ender lod, with since chand noling ond rade.\n",
      "\n",
      "rowisher:\n",
      "way oult us ie rofd me and so frise mfrathing loud.\n",
      "\n",
      "prine coake thie thit my of to preveo\n",
      "thy werst, theme seice me couend sous.\n",
      "\n",
      "jeatryour:\n",
      "nom shang: the goth tis bulinged \n",
      "ander, boast of this i can,\n",
      "though banise my buck loome cameald bong of ther.\n",
      "buseldes, and diles to goveus ason pancate.\n",
      "\n",
      "rifebre:\n",
      "in beas ame:\n",
      "oul ikerle this the is mapliad is and ti therd beous,\n",
      "aud heren wry couk, of ond it and unce wich and,\n",
      "ai, hom hade mace swalled hetromere henst!\n",
      "\n",
      "hee powil:\n",
      "bod yourd averdith:\n",
      "ald gors, but bou\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df4e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7410bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d9598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415e3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e87a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
